{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee25c57-af45-4b9f-93a5-f8faf25949b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162420f-4775-40a0-8fe5-d4d958d3b4d7",
   "metadata": {},
   "source": [
    "# INTRO TO TENSORS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f543e4-c4e0-437e-b1ec-3a4e1f82f9ef",
   "metadata": {},
   "source": [
    "A tensor is a mathematical tool that describes how different mathematical objects (like vectors) relate to each other in a linear manner across multiple dimensions. This means tensors can capture complex relationships that simple numbers, vectors, or matrices cannot.\r\n",
    "Key Characteristics\r\n",
    "Multilinear Relationships\r\n",
    "In practical terms, this means a tensor can:\r\n",
    "Map between different vector spaces\r\n",
    "Represent linear transformations\r\n",
    "Describe how quantities change across different directions\r\n",
    "Vector Space Context\r\n",
    "Tensors are not standalone objects but are fundamentally connected to vector spaces. They describe how quantities transform and interact within these spaces.\r\n",
    "Practical Example\r\n",
    "Consider electrical conductivity in a crystal. Instead of a simple one-to-one relationship between current and electric field, a tensor allows for more complex interactions:\r\n",
    "Current in one direction can depend on electric fields in multiple directions\r\n",
    "Each component can be linearly related to other components in a systematic way1\r\n",
    "Mathematical Depth\r\n",
    "At its most rigorous, a tensor can be defined as a multilinear map that transforms according to specific rules. This means it:\r\n",
    "Can represent relationships across multiple dimensions\r\n",
    "Maintains consistent transformation properties regardless of coordinate system24\r\n",
    "The beauty of tensors is their ability to generalize mathematical concepts from simple scalars to incredibly complex, multi-dimensional representations of physical and mathematical phenomena.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386bd267-85fe-4020-ad2b-89f86de7388b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309c65c8-67f9-4ae0-bdc3-03c35090cd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b3682c-4a73-489c-9d40-452dc3cb8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28399ad6-fb57-4433-a5e4-d80e0cedb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#vector\n",
    "vector = torch.tensor([3,5])\n",
    "print(vector.ndim, vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2bc175-16b2-4152-83f4-24c902757a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 8],\n",
      "        [6, 7],\n",
      "        [8, 9]]) 2 torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "matrix = torch.tensor([[7, 8],\n",
    "                      [6, 7],\n",
    "                      [8, 9]])\n",
    "print(matrix, matrix.ndim, matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8497a6d0-e8b4-48c3-bebc-3ddb8b381f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) 3 torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#updating torch to tensor\n",
    "tensor = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "print(tensor, tensor.ndim, tensor.shape) #from shapeinstance, rows, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f664094-7f9f-4091-9239-070690ea2d79",
   "metadata": {},
   "source": [
    "## RANDOM TENSORS \n",
    "\n",
    "random tensors are used for NN learning, tensors full of random numbers and then adjust it to those random numbers to better representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7218a000-f214-4180-90aa-f7a8591e0dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2100, 0.4592, 0.2641, 0.1679, 0.2456, 0.7115, 0.1912, 0.8633,\n",
      "          0.5085, 0.7652],\n",
      "         [0.5859, 0.7707, 0.2019, 0.6470, 0.3251, 0.7310, 0.6694, 0.0686,\n",
      "          0.0822, 0.9873],\n",
      "         [0.0943, 0.6505, 0.6217, 0.4992, 0.6844, 0.3609, 0.4589, 0.8007,\n",
      "          0.7932, 0.2167],\n",
      "         [0.2161, 0.3289, 0.7565, 0.7380, 0.9762, 0.1973, 0.3521, 0.4174,\n",
      "          0.9524, 0.4609],\n",
      "         [0.7195, 0.1889, 0.9984, 0.6196, 0.1302, 0.8796, 0.2148, 0.3943,\n",
      "          0.9945, 0.6622],\n",
      "         [0.9174, 0.6021, 0.7064, 0.3960, 0.7503, 0.2939, 0.6467, 0.4794,\n",
      "          0.3448, 0.0812]],\n",
      "\n",
      "        [[0.7314, 0.4307, 0.2879, 0.1587, 0.2972, 0.7200, 0.8714, 0.5774,\n",
      "          0.3313, 0.9472],\n",
      "         [0.9757, 0.0645, 0.4511, 0.6071, 0.9116, 0.2049, 0.5291, 0.6795,\n",
      "          0.7367, 0.5968],\n",
      "         [0.7735, 0.0474, 0.3455, 0.0260, 0.9573, 0.6704, 0.2936, 0.3244,\n",
      "          0.4518, 0.2288],\n",
      "         [0.8032, 0.0133, 0.1802, 0.0614, 0.5718, 0.0794, 0.6098, 0.7252,\n",
      "          0.3491, 0.5360],\n",
      "         [0.0173, 0.2325, 0.4722, 0.9909, 0.1859, 0.1475, 0.3559, 0.0121,\n",
      "          0.9418, 0.5747],\n",
      "         [0.3880, 0.6707, 0.6238, 0.4763, 0.3313, 0.1677, 0.2661, 0.2845,\n",
      "          0.0192, 0.2531]],\n",
      "\n",
      "        [[0.3946, 0.7550, 0.2244, 0.6907, 0.0704, 0.8393, 0.6277, 0.2112,\n",
      "          0.6923, 0.0642],\n",
      "         [0.6984, 0.7088, 0.2890, 0.7226, 0.3476, 0.9716, 0.7459, 0.8935,\n",
      "          0.0093, 0.4184],\n",
      "         [0.2430, 0.2463, 0.2751, 0.1661, 0.2862, 0.9941, 0.0207, 0.5389,\n",
      "          0.6875, 0.3675],\n",
      "         [0.9132, 0.0306, 0.4002, 0.7460, 0.7981, 0.0851, 0.4615, 0.4113,\n",
      "          0.8718, 0.4407],\n",
      "         [0.4829, 0.1254, 0.3599, 0.9183, 0.3070, 0.1336, 0.2014, 0.5169,\n",
      "          0.1524, 0.4102],\n",
      "         [0.8195, 0.7157, 0.8035, 0.4082, 0.9730, 0.3146, 0.7606, 0.4866,\n",
      "          0.9344, 0.6061]],\n",
      "\n",
      "        [[0.2215, 0.9130, 0.1349, 0.1148, 0.6937, 0.3770, 0.8322, 0.8815,\n",
      "          0.7925, 0.8795],\n",
      "         [0.1775, 0.9249, 0.8617, 0.8674, 0.5155, 0.1789, 0.9280, 0.9330,\n",
      "          0.6387, 0.4233],\n",
      "         [0.6859, 0.3972, 0.7364, 0.7977, 0.7688, 0.4100, 0.5270, 0.2757,\n",
      "          0.9519, 0.1030],\n",
      "         [0.4121, 0.4413, 0.5711, 0.4839, 0.1310, 0.1116, 0.3870, 0.7245,\n",
      "          0.7388, 0.3512],\n",
      "         [0.0451, 0.6199, 0.9533, 0.6411, 0.5819, 0.1119, 0.3742, 0.8263,\n",
      "          0.3078, 0.6530],\n",
      "         [0.4207, 0.6126, 0.4309, 0.2884, 0.8787, 0.4984, 0.7807, 0.2192,\n",
      "          0.9202, 0.3772]],\n",
      "\n",
      "        [[0.9583, 0.1279, 0.3377, 0.6178, 0.3987, 0.4391, 0.1202, 0.2172,\n",
      "          0.2792, 0.8211],\n",
      "         [0.0383, 0.4175, 0.5728, 0.2260, 0.2874, 0.9816, 0.2291, 0.1643,\n",
      "          0.5822, 0.3429],\n",
      "         [0.8560, 0.2795, 0.8709, 0.4024, 0.7995, 0.3533, 0.7227, 0.1463,\n",
      "          0.2487, 0.6854],\n",
      "         [0.9809, 0.0553, 0.8937, 0.2727, 0.8582, 0.2494, 0.3580, 0.0503,\n",
      "          0.0336, 0.9943],\n",
      "         [0.8714, 0.6349, 0.3221, 0.1148, 0.7862, 0.4117, 0.7139, 0.4980,\n",
      "          0.1611, 0.4998],\n",
      "         [0.1639, 0.1386, 0.2252, 0.7255, 0.7757, 0.3811, 0.2306, 0.6127,\n",
      "          0.2763, 0.9169]]]) 3 <built-in method size of Tensor object at 0x0000025C8BE772A0>\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(5,6, 10)\n",
    "print(random_tensor, random_tensor.ndim, random_tensor.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e20c06d-fdee-4f9b-9490-d100ba97fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))#ht, width, color channels\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6e39f-7648-405b-8e1c-1fb364daa92f",
   "metadata": {},
   "source": [
    "### TENSOR MANIPULATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d525c8-0345-4b96-9cae-fd968b7b45c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeros and ones\n",
    "zeros = torch.zeros(size=(5,6,10))\n",
    "p = zeros*random_tensor\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "337b040a-3a59-4d39-8c0a-e464800f6f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(5,6,10))\n",
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cbb17f8-78e0-441f-987e-c935c26876c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 40, 79])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a range of tensors and tensors-like\n",
    "hope = torch.arange(start=1,end=100,step=39)\n",
    "hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f87c99-a8e7-46f1-9aa0-3fa3650f54b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=hope)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec4e74-554a-41d9-b9ba-a95d0cd6d8a8",
   "metadata": {},
   "source": [
    "#### TENSOR DATATYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6662550b-3c07-4579-b2db-73297f664b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_t = torch.tensor([3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False)\n",
    "float_32_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f4cc0c3-11df-4605-8ebf-56c8be5ac37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_t = float_32_t.type(torch.half)\n",
    "float_16_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3796da36-92fd-48da-a601-4d2e557dd63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_t = torch.tensor([3,6,9], dtype = torch.long)\n",
    "int_32_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8cd692-01d4-4103-b850-176206967b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_t * int_32_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bf4d61-fc1c-4ad9-95bc-21d826388bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2831, 0.2654, 0.7318, 0.3904],\n",
       "        [0.8808, 0.2785, 0.4642, 0.4005],\n",
       "        [0.3435, 0.0167, 0.9194, 0.9335]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t = torch.rand(3,4)\n",
    "s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e42f16c7-cfe6-4c04-94bd-87a9203b202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2831, 0.2654, 0.7318, 0.3904],\n",
      "        [0.8808, 0.2785, 0.4642, 0.4005],\n",
      "        [0.3435, 0.0167, 0.9194, 0.9335]])\n",
      "dtype of tensor and shape:torch.float32, torch.Size([3, 4]), torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(s_t)\n",
    "print(f'dtype of tensor and shape:{s_t.dtype}, {s_t.shape}, {s_t.size()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcbf9db4-e905-4127-b1b9-83425f0f7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device tensor is on :cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'device tensor is on :{s_t.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49efe4b9-fae6-403c-915a-103d5cd7c01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method item of Tensor object at 0x0000025C8BE75C20>\n"
     ]
    }
   ],
   "source": [
    "#some random tensors\n",
    "tg = torch.rand((5,5), dtype = torch.float32, requires_grad=True, device = 'cuda').long()\n",
    "pg = torch.ones((5,5), dtype = torch.float64, requires_grad = True, device='cuda')\n",
    "cg = tg * pg\n",
    "print(cg.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "713972f2-f2b7-46ad-8b6d-0141c38f6952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aab270e-28b1-427b-a26b-50cd506435bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5058, 0.2337, 0.5131, 0.2154],\n",
      "          [0.8982, 0.0829, 0.7936, 0.6868],\n",
      "          [0.3216, 0.4216, 0.8504, 0.1089],\n",
      "          [0.9809, 0.1522, 0.7866, 0.1378]]]])\n",
      "op shape: torch.Size([1, 1, 2, 2])\n",
      "op tensor([[[[-1.9325,  1.8346],\n",
      "          [ 0.7008,  2.1413]]]])\n"
     ]
    }
   ],
   "source": [
    "ip_t = torch.rand([4,4], dtype = torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "kernel = torch.tensor([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "op = F.conv2d(ip_t, kernel)\n",
    "print(ip_t)\n",
    "print('op shape:', op.shape)\n",
    "print('op', op)\n",
    "#(1,1,2,2) -> batch size, no of channels, height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8461fb-c630-40cf-a8de-fab2b0033f32",
   "metadata": {},
   "source": [
    "#### TENSOR OPERATIONS \n",
    "all arithmetic and matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1185b9ed-3f70-4784-86ca-d1b5cc683291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([104, 105, 106]) tensor([400, 500, 600]) tensor([0, 1, 1]) tensor([0, 1, 2]) tensor([0.4000, 0.5000, 0.6000])\n"
     ]
    }
   ],
   "source": [
    "# addition \n",
    "tensor = torch.tensor([4,5,6])\n",
    "p = tensor+100\n",
    "q = tensor * 100\n",
    "r = tensor // 5\n",
    "s = tensor % 4\n",
    "t = tensor / 10\n",
    "print(p,q,r,s,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d64764-f1dc-44ef-ae19-f2b1e033237f",
   "metadata": {},
   "source": [
    "#### MATRIX MULTIPLICATION \n",
    "1. inner dimentions must match\n",
    "2. resulting matrix has the shape of the outer dimentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c864d8ab-f2f6-4a80-bc09-bbc7d6df84f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6])  *  tensor([4, 5, 6])\n",
      "equals: tensor([16, 25, 36])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, ' * ', tensor)\n",
    "print(f'equals: {tensor * tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c6c3eb-96e0-44cb-9a3a-4660d78bb025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(77)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2911dcb4-c572-4d4a-86fb-41c2075921d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77)\n"
     ]
    }
   ],
   "source": [
    "value = 0 \n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21470aaa-6cf2-4a07-8a29-577cbd16bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(77)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2713bf33-70ac-47a4-aa83-f252194744d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(77)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6fdc5fb-6c4a-4f82-ab26-f6632a1c5279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1231, 0.1782, 0.0956],\n",
       "        [0.1456, 0.5733, 0.2948],\n",
       "        [0.5035, 1.0176, 0.5356]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3,2), torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c87e5-4edc-415c-9903-80ca1c17dc1e",
   "metadata": {},
   "source": [
    "#### Most common errors in DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5edeaed8-d2c3-4688-983f-f53ba1c53712",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor_a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                        [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                        [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[0;32m      4\u001b[0m tensor_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      5\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      6\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m----> 7\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(tensor_a, tensor_b)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]])\n",
    "tensor_b = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "torch.mm(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea090d-f034-4b04-ba86-63eec4e234f9",
   "metadata": {},
   "source": [
    "to fix the above issue, we can use Transpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6635488-7c8d-484a-a701-4f2586216a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = tensor_b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e83e2bfb-3dda-424e-bf5c-4b38b9f7ee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_a, transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0619f336-89cb-441a-b3b8-1907cc27203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shapes: tensor_a =torch.Size([3, 2]), tensor_b = torch.Size([3, 2])\n",
      "new shapes: tensor_a = torch.Size([3, 2]), tensor_b =torch.Size([2, 3])\n",
      "multiplying: torch.Size([3, 2]) @ torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'original shapes: tensor_a ={tensor_a.shape}, tensor_b = {tensor_b.shape}')\n",
    "print(f'new shapes: tensor_a = {tensor_a.shape}, tensor_b ={transpose.shape}')\n",
    "print(f'multiplying: {tensor_a.shape} @ {transpose.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905b9e5-9f26-4cbf-bf9f-6c485a28bcf8",
   "metadata": {},
   "source": [
    "## TENSOR AGGREGATION \n",
    "1.MIN\n",
    "2.MAX\n",
    "3.SUM , etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1ab5559-cf11-4c1e-9d9b-6284baead99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor \n",
    "x = torch.arange(0, 100, 10)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770ed00b-e5dc-4736-b013-b4924f8f8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b41fa3a-b890-490d-8e26-406baa57b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), <function Tensor.max>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "610666ab-ae99-4246-bd7e-d13dc3c85b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c4d93b0-f8fb-4455-beeb-a2c9fec11fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8f0c549-8fe4-4268-a93f-6e163bdd2319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#argmax and argmin, for finding postitional min and max\n",
    "print(x.argmax(),x.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c92a8-ded5-4190-bf71-39c60e9d4a3e",
   "metadata": {},
   "source": [
    "#### RESHAPE. VIEW AND STACK TENSORS, squeezing and un-squeezing \n",
    "1. reshaping - reshape an ip tensor to a defined shape\n",
    "2. view - return a view of an ip tensor of certain shape but keep the same mem as the original tensor\n",
    "3. stacking - combine multiple tensors on top of each other (vstack) or by side (hstack)\n",
    "4. squeeze - remove all 1 dim from a tensors\n",
    "5. unsqueeze - add a 1 dim to a tensor\n",
    "6. permute - return a view of ip with a dims permuted (swapped) in certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97bedd6e-b4e0-4c65-9ec1-d8124f5887b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1., 10,)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c31e3e24-5d71-40e9-809b-208d5c92158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "re_shape = x.reshape(3,3)\n",
    "re_shape, re_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5d2e5cc-f126-420b-8dde-3442cdc6e131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape\n",
    "#changing z changes the x (original view of a tensor shares the same mem as the original\n",
    "z[:, 0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ce6bbca-0a9f-4c0d-ab76-05f4d4bf2558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack tensors one on each other\n",
    "x_stack = torch.stack([x,x,x,x], dim=0)\n",
    "x_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10179935-2bd5-4bec-9553-75674bfefedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezing and unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35ca4018-b118-4279-b5cf-4686e7f03e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_shape.squeeze().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e78fe33c-c7c7-454a-b760-d9ad17ad5ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch unsqueeze\n",
    "re_shape.unsqueeze(dim=0).unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cffccdd-1fd9-48e5-bf2d-689627fb743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#premute - rearrange target tensor in specififed order\n",
    "p = torch.rand(size = (224, 224, 3))\n",
    "p.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e4b71e6-f8cd-4522-bae3-3a1a4c585eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = p.permute(2,0,1)\n",
    "l.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67f190-96e0-4863-8d54-e37ee2177cfd",
   "metadata": {},
   "source": [
    "### INDEXING (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c467b8c-4140-40f7-9352-423a47a63fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ceab60f-a853-473e-807b-e19032f66c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42dae0cb-cd79-4e08-8c2e-45220c823721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5a91e1f-2f43-44c7-9420-f45d9aaa7b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86b1555d-b4b5-4c4d-a286-2728f8351241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfeb61-57af-4c8c-87f5-f00be59ac2b3",
   "metadata": {},
   "source": [
    "### torch to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba6ca184-6640-48e0-b5ab-7320eaa0c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e77af422-d221-4132-b4da-e2aec6dfea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50843654-b3b5-4ace-91da-b5fadc13cec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "524b707e-e7ed-46de-955d-97505f3ef76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor to numpy array \n",
    "tensor = torch.ones(7)\n",
    "nupy_t = tensor.numpy()\n",
    "tensor, nupy_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de6041-e55c-41c6-9bec-df427bb07528",
   "metadata": {},
   "source": [
    "### REPRODUCIABILITY trying to take the random out of random\n",
    "to reduce the randomness in NN, pytorch comesup with --> random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b1b0230-b39e-4518-b85d-136734f581f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0708, 0.6916, 0.1160, 0.1454],\n",
      "        [0.5728, 0.2570, 0.7093, 0.7959],\n",
      "        [0.0361, 0.1320, 0.9546, 0.8293]]) tensor([[0.5494, 0.5430, 0.8311, 0.9059],\n",
      "        [0.3069, 0.9291, 0.6199, 0.6379],\n",
      "        [0.1086, 0.9584, 0.8488, 0.2406]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "random_te = torch.rand(3,4)\n",
    "random_ta = torch.rand(3,4)\n",
    "print(random_ta, random_te)\n",
    "print(random_te==random_ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8150bd3b-acb6-4f3a-b511-71fa7e1eb7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#random but reproduciable tensors\n",
    "import torch \n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "random_ta = torch.rand(3,4)\n",
    "torch.manual_seed(random_seed)\n",
    "random_te = torch.rand(3,4)\n",
    "\n",
    "print(random_ta, random_te)\n",
    "print(random_ta == random_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6595b-6987-44db-9e56-053e8ef4eb77",
   "metadata": {},
   "source": [
    "# ACCESSING GGPPUU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "122a6411-5016-4797-8265-69e2e0351805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 15 21:39:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 556.12                 Driver Version: 556.12         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce MX330         WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   64C    P8             N/A / ERR!  |       0MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1344      C   ...L\\anaconda3\\envs\\pytorch\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11b8775f-2d14-4db7-81d2-ba848c01e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the GPU access with pytorch\n",
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec036f-c668-47c3-93e6-7be4bc6be337",
   "metadata": {},
   "source": [
    "# setting up device agostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1a0a3c0-a085-43a8-94de-fde001ab7d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5e8ba2b-e098-448c-8742-07edad7908b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51fac8f4-3a0b-4b76-b8e6-2d28d91f0612",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/notes/cuda.html\n",
    "cuda semantics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77e377c7-7cc1-4037-8f36-7dda75f56be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agnositic code\n",
    "import argparse\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9320b8a1-a334-46b8-9d51-157e83392666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--disable-cuda]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\DELL\\AppData\\Roaming\\jupyter\\runtime\\kernel-6d08993f-6722-4bfe-a362-384592b54087.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Pytorch')\n",
    "parser.add_argument('--disable-cuda', action='store_true', help='Disable CUDA')\n",
    "args = parser.parse_args()\n",
    "args.device = None\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "else:\n",
    "    args.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "647f2a8a-16ad-4234-9890-8a2d12cf626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "#create a tensor, default is on GPU\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ada1a81-fe14-4a2d-ad3a-778e31911765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_g = tensor.to(device)\n",
    "tensor_on_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "696c91ed-eab5-4d79-aa90-41bfe9369b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## moving tensors back to CPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tensor_on_g\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "## moving tensors back to CPU\n",
    "tensor_on_g.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fb18394-003f-420d-8ec3-dbdbf77fff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#to fix the above error\n",
    "tensor_b_cp = tensor_on_g.cpu().numpy()\n",
    "print(tensor_b_cp,tensor_on_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897291a5-35e7-43e6-955c-8cd7f991fefe",
   "metadata": {},
   "source": [
    "# EXERCISES WITH SOLUTIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb25a5-9122-49b4-9989-63a3a9688c46",
   "metadata": {},
   "source": [
    "### 2. Create a random tensor of shape (7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "476b5ead-8d6d-49c6-b1a7-74d4133312c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1587, 0.6542, 0.3278, 0.6532, 0.3958, 0.9147, 0.2036],\n",
       "        [0.2018, 0.2018, 0.9497, 0.6666, 0.9811, 0.0874, 0.0041],\n",
       "        [0.1088, 0.1637, 0.7025, 0.6790, 0.9155, 0.2418, 0.1591],\n",
       "        [0.7653, 0.2979, 0.8035, 0.3813, 0.7860, 0.1115, 0.2477],\n",
       "        [0.6524, 0.6057, 0.3725, 0.7980, 0.8399, 0.1374, 0.2331],\n",
       "        [0.9578, 0.3313, 0.3227, 0.0162, 0.2137, 0.6249, 0.4340],\n",
       "        [0.1371, 0.5117, 0.1585, 0.0758, 0.2247, 0.0624, 0.1816]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "tensor = torch.rand(7,7)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7e4b4-cd74-4b8e-97ff-1209857c0bcb",
   "metadata": {},
   "source": [
    "### 3.Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0651018-1239-45d1-9fa0-b45685ac5d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1699],\n",
      "        [1.6426],\n",
      "        [1.5418],\n",
      "        [1.9253],\n",
      "        [1.8467],\n",
      "        [1.4598],\n",
      "        [0.6740]]) tensor([[0.6258, 0.2849, 0.4452, 0.1258, 0.9554, 0.1330, 0.7672]]) tensor([[0.6258],\n",
      "        [0.2849],\n",
      "        [0.4452],\n",
      "        [0.1258],\n",
      "        [0.9554],\n",
      "        [0.1330],\n",
      "        [0.7672]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "tensor2 = torch.rand(1,7)\n",
    "tensor_T = tensor2.t()\n",
    "matrix = torch.matmul(tensor, tensor_T)\n",
    "print(matrix, tensor2, tensor_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a0fd3-3269-4f40-8f46-29b85383b4cc",
   "metadata": {},
   "source": [
    "### 4. set the random seed to 0 and do 2 & 3 over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0ecbbe2-53a0-48dd-a061-028e967d3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9623],\n",
      "        [0.7606],\n",
      "        [0.2981],\n",
      "        [0.4291],\n",
      "        [0.9418],\n",
      "        [0.8212],\n",
      "        [0.6247]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed(456) #for GPU 5\n",
    "x = torch.rand(7,7)\n",
    "y = torch.rand(1,7)\n",
    "Y_t = y.t()\n",
    "print(Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b09c69-f8d0-40ee-98c0-b52fbe92fb03",
   "metadata": {},
   "source": [
    "### 6.Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1649d9de-94b0-46a0-9e9f-0001f47f4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1249, 0.2243, 0.8818],\n",
       "         [0.2896, 0.0343, 0.2301]], device='cuda:0'),\n",
       " tensor([[0.8655, 0.0829, 0.7657],\n",
       "         [0.7015, 0.0255, 0.4623]], device='cuda:0'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(2345)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device : {device}')\n",
    "t1 = torch.rand(2,3).to(device)\n",
    "t2 = torch.rand(2,3).to(device)\n",
    "t1, t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99207e-1b6f-49a4-98f1-2d1d0e8a716e",
   "metadata": {},
   "source": [
    "### 7.Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f33d6fa-9af0-43c7-b3b1-fa6bf1a9b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1495, 0.8882],\n",
      "        [0.7950, 0.3683]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "t1 = torch.rand(2,3)\n",
    "t2 = torch.rand(2,3)\n",
    "T = t2.t()\n",
    "mat = torch.matmul(t1, T)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e432374-02d5-4102-a5bc-ce4da9edf860",
   "metadata": {},
   "source": [
    "### 8.Find the maximum and minimum values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0034b3ed-7b80-4364-91fb-4355ec784b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3683), tensor(1.1495))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "min = torch.min(mat)\n",
    "max = torch.max(mat)\n",
    "min, max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002fc0f2-d178-4bbf-87b1-86d22be1c412",
   "metadata": {},
   "source": [
    "### 9. Find the maximum and minimum index values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "95b14fe8-5c51-47a2-b05d-763c571b3554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(3))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "argmax = torch.argmax(mat)\n",
    "argmin = torch.argmin(mat)\n",
    "argmax, argmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eeca23-fa35-4011-8d8c-8fb14aacd0ae",
   "metadata": {},
   "source": [
    "### 10.Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9aa1253-faab-42e8-92bd-85ba1a677858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) <built-in method size of Tensor object at 0x0000025C9FBF7430>\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) <built-in method size of Tensor object at 0x0000025C9FBF7AC0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(7)\n",
    "g = torch.rand(size=(1,1,1,10))\n",
    "d = g.squeeze()\n",
    "print(g, g.size)\n",
    "print(d, d.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856cc11-0abb-4719-8cbe-62c7c3596b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
